\documentclass[11pt]{article}

\usepackage{amsmath} % Required for \eqref
\usepackage{amssymb} % Required for \mathbb
\usepackage{units}   % Required for \nicefrac
\usepackage{float}   % Required for algorithm and floating environments
\usepackage{graphicx}% Required for figures and imagesf

%-------------------------------------------
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{acknowledgment}[theorem]{Acknowledgment}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
%-------------------------------------------
\floatstyle{ruled}
\newfloat{program}{thp}{lop}
\floatname{program}{Algorithm}
%-------------------------------------------
\newcommand{\diag}{\ensuremath{\mathrm{diag}}}
\newcommand{\MSE}[1]{\ensuremath{\mathrm{MSE}\left(#1\right)}}
\newcommand{\trace}[1]{\ensuremath{\mathrm{trace}\left( #1 \right)}}
\newcommand{\norm}[1]{\ensuremath{\left\|#1\right\|_2^2}}
\newcommand{\func}[2]{\ensuremath{\mathrm{#1}\left( #2 \right)}}
\newcommand{\normzero}[1]{\ensuremath{\left\|#1\right\|_0}}
\newcommand\eps \epsilon
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand\RR[1]{\mathbb{R}^{#1}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\real}{\ensuremath{\mathbb{R}}}
\newcommand{\conv}{\ensuremath{\ast}}
\newcommand{\cl}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\suppsize}[1]{\ensuremath{|\mathcal{#1}|}}
\newcommand{\vect}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\matr}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\mat}[2]{\left(\begin{array}{#1}#2\end{array}\right)}
\newcommand{\brc}[2]{\left\{\begin{array}{#1}#2\end{array}\right.}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathrsfs}

\providecommand\Laplacian{\nabla^2}
\providecommand\bnabla{\boldsymbol{\nabla}}
\providecommand\bcdot{\boldsymbol{\cdot}}
\providecommand\bv{\boldsymbol{v}}
\providecommand\bV{\boldsymbol{V}}
\providecommand\be{\boldsymbol{\hat{e}}}
\providecommand\bn{\boldsymbol{\hat{n}}}
\providecommand\bk{\boldsymbol{\hat{k}}}
\providecommand\bj{\boldsymbol{j}}
\providecommand\bi{\boldsymbol{i}}
\providecommand\bI{\boldsymbol{I}}
\providecommand\bJ{\boldsymbol{J}}
\providecommand\bx{\boldsymbol{x}}
\providecommand\bzero{\boldsymbol{0}}

\providecommand\tI{\mathsf{I}}
\providecommand\tS{\mathsfbi{S}}
\providecommand\unit{\boldsymbol{\hat{\imath}}}

\providecommand\dd{\mathrm{d}}
\providecommand\ee{\mathrm{e}}

\setlength{\textheight}{8.7in}
\setlength{\columnsep}{2.0pc}
\setlength{\textwidth}{6.6in}
% \setlength{\footheight}{0.2in}
\setlength{\topmargin}{0.05in}
\setlength{\headheight}{0.2in}
\setlength{\headsep}{0.1in}
\setlength{\evensidemargin}{0in}
\setlength{\oddsidemargin}{0in}
% \setlength{\parindent}{1pc}
\setlength{\parindent}{0.0 in}
\setlength{\parskip}{0.1 in}
\title{Notes on PDE numerics}
\begin{document}
\maketitle
\section{Diffusion}
\subsection{Laplace equation (follows from Gauss' law)}
The electric potential satisfies the elliptic equation
\begin{equation}
	\bnabla \bcdot (C \bnabla \varPhi) = 0; \label{Phi eqn}
\end{equation}
$C$ is salt concentration, playing the role of $\eps$,
in Maxwell's equation (where $\vect{E} = -\bnabla \varPhi$):
\begin{equation}
\bnabla \bcdot \vect{D} = \bnabla \bcdot \eps \vect{E} = \rho_{free}
\end{equation}

We assume regular grid $\{(x_i, y_j)\}$,
where $i\in\{0 \ldots n\}$ and $j\in\{0 \ldots m\}$. The maximal and the
minimal indices' values correspond to the boundary of the problem.

We approximate the differential operator as:
\begin{eqnarray}
\left[ \bnabla \bcdot (C \bnabla \varPhi) \right]_{i,j}
&\approx &\frac{2}{x_{i+1,j} - x_{i-1,j}} \left(
C_{i+1/2,j} \cdot \frac{\varPhi_{i+1,j}-\varPhi_{i,j}}{x_{i+1}-x_{i}} -
C_{i-1/2,j} \cdot \frac{\varPhi_{i,j}-\varPhi_{i-1,j}}{x_{i}-x_{i-1}}
\right) + \\
&&\frac{2}{y_{i,j+1} - y_{i,j-1}} \left(C_{i,j+1/2} \cdot \frac{\varPhi_{i,j+1}-\varPhi_{i,j}}{y_{i+1}-y_{i}} -
C_{i,j-1/2} \cdot \frac{\varPhi_{i,j}-\varPhi_{i,j-1}}{y_{i}-y_{i-1}}
\right)
\end{eqnarray}
where $2C_{i\pm 1/2,j} = C_{i,j} + C_{i\pm 1,j}$ and
$2C_{i,j\pm 1/2} = C_{i,j} + C_{i,j\pm 1}$.

The algebraic system above can be written as $\matr{A} \vect{u} = \vect{f}$,
where $\matr{A}$ depends on the grid and current $C$ values.
$\vect{f}$ can be chosen to be any function, which is useful for testing the solver.
We initialize $\vect{u}$ to any function, and employ Jacobi iterations
(by writing $\matr{A} = \matr{D} + (\matr{A-D})$, where $\matr{D}$ is diagonal):
\begin{eqnarray}
\vect{f} &=& \matr{A}\vect{u} = \matr{D}\vect{u} + (\matr{A-D})\vect{u} \\
\matr{D}\vect{u} &=& \vect{f} - (\matr{A-D})\vect{u} =
\vect{f} - \matr{A}\vect{u} + \matr{D}\vect{u} \\
\vect{u}_+ &=& \vect{u} + \matr{D}^{-1}(\vect{f} - \matr{A}\vect{u}) =
(\matr{I} - \matr{D}^{-1}\matr{A}) \vect{u} + \matr{D}^{-1}\vect{f} \\
\end{eqnarray}
Therefore, we shall use the following iteration scheme:
\begin{eqnarray}
\vect{u}_+ &=& \matr{T}\vect{u} + \vect{d} \\
\matr{T} &=& \matr{I} - \matr{D}^{-1}\matr{A} \\
\vect{d} &=& \matr{D}^{-1}\vect{f}
\end{eqnarray}
To speed-up the convergence, we shall use Red-Black Gauss-Seidel method,
that updates ``odd'' and ``even'' elements of $\vect{u}$, solving
effectively the linear system for half the variables each time.
\subsection{Boundary conditions}
\subsubsection{Dirichlet}
The condition is given as $U(x, y) = C$.
We take $u_k = U(x_i, y_j) = C$.
Now, it is simply substituted and
linear system's right-hand side is updated accordingly.

\subsubsection{Neumann}
The condition is given as $\bnabla U(x,y) \cdot \vect{\hat n} = C$,
where $\vect{\hat n}$ is normal to domain's boundary.
If we use quadratic approximation, the gradient can be expressed as:
\begin{eqnarray}
  f(x) &=& ax^2 + bx + c \\
  f(x_0 \pm \Delta x) &=&
   a(x_0 \pm \Delta x)^2 + b(x_0 \pm \Delta x) + c \\
  \frac{f(x_0 + \Delta x) - f(x_0 - \Delta x)}{2\Delta x} &=&
   2a x_0 + b = f'(x_0) \\
\end{eqnarray}
Therefore, the boundary value can be approximated by:
\begin{eqnarray}
 U(x + \Delta x,y + \Delta y) &\approx& U(x, y) + \partial_x U(x_c,y_c) \Delta x +
 \partial_x U(x_c,y_c) \Delta y \\
 x_c &=& x + \frac{\Delta x}{2} \\
 y_c &=& y + \frac{\Delta y}{2}
\end{eqnarray}

\subsection{Specific boundary conditions}
\subsubsection{$R = 1$}
\begin{eqnarray}
  \frac{\partial C}{\partial R} &=&
   C \frac{\partial \varPhi}{\partial R} \\
  \varPhi &=& \mathscr{V} - \ln C + \ln \gamma
\end{eqnarray}
Take $\mathscr{V} = -\ln \gamma$ and note that:
\begin{eqnarray}
  \frac{\partial}{\partial R} \ln C &=&
  \frac{1}{C}\frac{\partial C}{\partial R} =
  \frac{\partial \varPhi}{\partial R} \\
  \varPhi &=& -\ln C
\end{eqnarray}
Use ghost-point \#0 to write the following boundary equations:
\begin{eqnarray}
  \varPhi_1 - \varPhi_0 &=& \ln C_1 - \ln C_0 \\
  \varPhi_1 + \varPhi_0 &=& - \ln C_1 - \ln C_0
\end{eqnarray}
Add and subtract to get 2 Dirichlet conditions:
\begin{eqnarray}
  \varPhi_1 &=& - \ln C_0 \\
  \varPhi_0 &=& - \ln C_1 \\
  C_0 &=& e^{-\varPhi_1}
\end{eqnarray}
\subsubsection{$R \rightarrow \infty$}
$C$ gets uniform, and we get Dirichlet:
\begin{eqnarray}
 C = 1
\end{eqnarray}
The field radial component is Neumann:
\begin{eqnarray}
 \frac{\partial \varPhi}{\partial R} = -\mathscr{E} \cos \theta
\end{eqnarray}
\subsubsection{$\Theta = 0/\pi$}
Using symmetry considerations, we have Neumann conditions:
\begin{eqnarray}
 \frac{\partial \varPhi}{\partial \Theta} &=& 0 \\
 \frac{\partial C}{\partial \Theta} &=& 0 \\
\end{eqnarray}

\section{Advection}
\subsection{Differential equation}
\begin{equation}
	\bnabla^2 C - \alpha \mathbf{V} \bcdot \bnabla C = 0	
\end{equation}

\subsection{1D example}
\begin{eqnarray}
  f'' - \alpha f' = 0 \\
  f(0) = 0 \\ f(1) = 1
\end{eqnarray}
Use $f(x) = e^{\gamma x}$ so $\gamma \in \{0, \alpha\}$ so:
\begin{eqnarray}
  f(x) &=& Ae^{\alpha x} + B \\
  0 &=& A + B \\
  1 &=& Ae^{\alpha} + B
\end{eqnarray}
The continuous solution is:
\begin{eqnarray}
  f(x) &=& \frac{e^{\alpha x} - 1}{e^{\alpha} - 1}
\end{eqnarray}

\subsection{Central difference}
We start by using the following scheme:
\begin{eqnarray}
  \frac{f_{k-1}-2f_k+f_{k+1}}{h^2}
  - \alpha \frac{f_{k+1}-f_{k-1}}{2h} &=& 0 \\
(f_{k-1}-2f_k+f_{k+1}) - \eps (f_{k+1}-f_{k-1}) &=& 0 \\
\eps = \frac{\alpha h}{2} \\
(1-\eps)f_{k-1}-2f_k+(1+\eps)f_{k+1} &=& 0
\end{eqnarray}
Write $f_k = \gamma^k$ to get:
\begin{eqnarray}
  (1-\eps)\gamma^{k-1} - 2\gamma^k + (1+\eps)\gamma^{k+1}&=& 0 \\
  (1-\eps)\gamma - 2\gamma + (1+\eps)\gamma^2&=& 0 \\
  \gamma = \frac{1 \pm \sqrt{1 - (1-\eps)(1+\eps)}}{1+\eps}
         = \frac{1 \pm |\eps|}{1+\eps} \in
           \left\{1, \frac{1- \eps}{1+\eps}\right\}
\end{eqnarray}
Take $f_0 = 0$ and $f_N = 1$ such that $h N = 1$, so:
\begin{eqnarray}
  f_k &=& \frac{1 - \left(\frac{1- \eps}{1+\eps}\right)^k}
  {1 - \left(\frac{1- \eps}{1+\eps}\right)^N}
\end{eqnarray}
Denote $x = \frac{k}{N}$ for $|\eps| < 1$:
\begin{eqnarray}
(1+\eps)^k = \left(1+\frac{\alpha h}{2}\right)^k =
\left(1+\frac{\alpha}{2N}\right)^k =
\left(1+\frac{\frac{\alpha k}{2N}}{k}\right)^k \approx
e^{\frac{\alpha k}{2N}} = e^{\frac{\alpha x}{2}}
\end{eqnarray}
So:
\begin{eqnarray}
  \left(\frac{1- \eps}{1+\eps}\right)^k &\approx& e^{\alpha x} \\
  f_k &\approx& \frac{1 - e^{\alpha x}}{1 - e^{\alpha}}
\end{eqnarray}
Otherwise ($h > 2/|\alpha|$), we get an oscillating solution, since $\gamma < 0$.
\subsection{Upwind difference}
We write:
\begin{eqnarray}
\frac{f_{k-1}-2f_k+f_{k+1}}{h^2} - \alpha \frac{f_k - f_{k-1}}{h} &=& 0 \\
(f_{k-1}-2f_k+f_{k+1}) - \alpha h (f_k - f_{k-1}) &=& 0 \\
(1 + 2\eps)f_{k-1}- (2 + 2\eps)f_k + f_{k+1} &=& 0 \\
2\eps = \alpha h
\end{eqnarray}
Again, write $f_k = \gamma^k$ to get:
\begin{eqnarray}
 \gamma^2 - (2 + 2\eps) \gamma + (1 + 2\eps) &=& 0
\end{eqnarray}
\begin{eqnarray}
\gamma &=& 1+\eps \pm \sqrt{(1+\eps)^2 - 1 - 2\eps} = 1 + \eps \pm |\eps| \in \{1, 1+2\eps\}
\end{eqnarray}
Given $\alpha > 0$, we note that there are no oscillations since $\gamma > 0$.

Moreover, the solution for $f_0 = 0$ and $f_N = 1$ (where $h N = 1$) is:
\begin{eqnarray}
f_k &=& \frac{1 - (1+2\eps)^k}{1 - (1+2\eps)^N}
\end{eqnarray}
Since $(1+2\eps)^k = (1+\alpha h)^k = \left(1 + \frac{\alpha}{N}\right)^k \approx e^{\alpha x}$ for $x = k/N$
so we get that $f_k \rightarrow f(x)$, as desired.
\subsection{Second order upwind scheme}
Suppose $f(x) = ax^2 + bx + c$:
\begin{eqnarray}
  f(0) &=& c \\
  f(-h) &=& ah^2 - bh + c \\
  f(-2h) &=& 4ah^2 - 2bh + c
\end{eqnarray}
Note that:
\begin{eqnarray}
  f(0) - f(-h) &=& bh - ah^2 \\
  f(0) - f(-2h) &=& 2bh - 4ah^2
\end{eqnarray}
This way we get 2nd order upwind approximation for the derivative $f'(0) = b$:
\begin{eqnarray}
  2bh &=& 4\left\{f(0) - f(-h)\right\} - \left\{f(0) - f(-2h)\right\} \\
  b &=& \frac{3f(0) - 4f(-h) + f(-2h)}{2h}
\end{eqnarray}

\section{Polar Coordinates}
\begin{eqnarray}
\bnabla f &=& \frac{\partial f}{\partial r} \mathbf{\hat{r}} +
\frac{1}{r} \frac{\partial f}{\partial \theta} \mathbf{\hat{\theta}}
\\
\bnabla \mathbf{\cdot} \mathbf{F} &=& \frac{1}{r}
\left(
\frac{\partial}{\partial r} (r F_r) +
\frac{\partial F_\theta}{\partial \theta}
\right)
\\
\bnabla^2 f &=& \frac{1}{r}\frac{\partial}{\partial r}
\left( r \frac{\partial f}{\partial r} \right) +
\frac{1}{r^2}\frac{\partial^2 f}{\partial \theta^2}
\end{eqnarray}

\section{Stokes}
\begin{eqnarray}
 \bnabla P - \mu \Delta \mathbf{V} &=& \mathbf{F} \\
 \bnabla \bcdot \mathbf{V} &=& 0
\end{eqnarray}
The following system is built:
\begin{eqnarray}
 \mat{ccc}{-\mu\Delta & 0 & \partial_x \\ 0 & -\mu\Delta & \partial_y \\ \partial_x & \partial_y & 0}
 \mat{c}{V_x \\ V_y \\ P} &=& \mat{c}{F_x \\ F_y \\ 0}
\end{eqnarray}

\section{Vanka}
\begin{eqnarray}
 r &=& f - Ax \\
 Px &\leftarrow& Pf - (PA - PAP^T P)x \\
 x &\leftarrow& \sum_P P^T (PAP^T)^{-1} P (f - A(I - P^T P)x) \\
 x &\leftarrow& \sum_P P^T (PAP^T)^{-1} P (f - Ax + AP^T Px) \\
 x &\leftarrow& \sum_P P^T (PAP^T)^{-1} P r + \sum_P P^T (PAP^T)^{-1} P AP^T Px \\
 x &\leftarrow& (\sum_P P^T (PAP^T)^{-1} P) r + (\sum_P P^T P)x \\
 x &\leftarrow& x + \left(\sum_i P_i^T \left(P_iAP_i^T\right)^{-1} P_i\right) (f - Ax)
\end{eqnarray}

%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
